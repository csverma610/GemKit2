{
  "metadata": {
    "title": "Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models",
    "authors": [
      "Qizheng Zhang",
      "Changran Hu",
      "Shubhangi Upasani",
      "Boyuan Ma",
      "Fenglu Hong",
      "Vamsidhar Kamanuru",
      "Jay Rainton",
      "Chen Wu",
      "Mengmeng Ji",
      "Hanchen Li",
      "Urmish Thakker",
      "James Zou",
      "Kunle Olukotun"
    ],
    "abstract": "Large language model (LLM) applications such as agents and domain-specific reasoning increasingly rely on context adaptation—modifying inputs with instructions, strategies, or evidence, rather than weight updates. Prior approaches improve usability but often suffer from brevity bias, which drops domain insights for concise summaries, and from context collapse, where iterative rewriting erodes details over time. Building on the adaptive memory introduced by Dynamic Cheatsheet, we introduce ACE (Agentic Context Engineering), a framework that treats contexts as evolving playbooks that accumulate, refine, and organize strategies through a modular process of generation, reflection, and curation. ACE prevents collapse with structured, incremental updates that preserve detailed knowledge and scale with long-context models. Across agent and domain-specific benchmarks, ACE optimizes contexts both offline (e.g., system prompts) and online (e.g., agent memory), consistently outperforming strong baselines: +10.6% on agents and +8.6% on finance, while significantly reducing adaptation latency and rollout cost. Notably, ACE could adapt effectively without labeled supervision and instead by leveraging natural execution feedback. On the AppWorld leaderboard, ACE matches the top-ranked production-level agent on the overall average and surpasses it on the harder test-challenge split, despite using a smaller open-source model. These results show that comprehensive, evolving contexts enable scalable, efficient, and self-improving LLM systems with low overhead.",
    "keywords": null,
    "field_of_study": "Machine Learning, Natural Language Processing, AI Agents",
    "paper_type": "research"
  },
  "executive_summary": {
    "summary": "This paper introduces Agentic Context Engineering (ACE), a novel framework that addresses key limitations in current context adaptation methods for large language models. ACE proposes treating contexts as evolving playbooks, employing a modular generation, reflection, and curation process with structured, incremental updates to prevent brevity bias and context collapse. The framework demonstrates significant performance gains—10.6% on agents and 8.6% on finance benchmarks—while substantially reducing adaptation latency and cost, even matching or exceeding top-tier proprietary models with smaller open-source LLMs. Its ability to adapt without labeled supervision using natural execution feedback highlights its potential for scalable and self-improving AI systems, although its reliance on strong feedback signals for optimal performance is a noted limitation."
  },
  "methodology": {
    "rating": "excellent",
    "soundness": "The methodology is sound, built upon a clear theoretical foundation extending Dynamic Cheatsheet [41] by introducing a modular agentic architecture (Generator, Reflector, Curator) as described in Section 3. The principles of incremental delta updates (§3.1) and grow-and-refine mechanisms (§3.2) are logically consistent and designed to address identified limitations of prior work, such as context collapse and brevity bias.",
    "experimental_design": "The experimental design is robust, evaluating ACE on two distinct categories of LLM applications: agent benchmarks (AppWorld [43]) and domain-specific benchmarks (FiNER [33], Formula [44]) as detailed in Section 4.1. The comparison includes strong baselines like ICL [3], MIPROv2 [36], GEPA [4], and Dynamic Cheatsheet [41], using both offline and online adaptation settings. Ablation studies (Table 3) provide insights into the contribution of individual design choices.",
    "statistical_rigor": "The paper demonstrates statistical rigor by reporting average performance gains with standard deviation, e.g., in Table 1 and Table 2, where results are presented as \"value±error.\" This indicates the variability and reliability of the reported improvements over multiple runs or splits, enhancing the credibility of the findings.",
    "reproducibility": "The paper discusses reproducibility by stating the use of the DeepSeek-V3.1 model and referencing official implementations for baselines (e.g., ReAct [52], DSPy [14, 15], Dynamic Cheatsheet [42]). However, explicit mention of ACE's code availability or detailed hyperparameters for full reproduction is limited, although prompts for ICL, GEPA, DC, and ACE are provided in Appendix D.",
    "strengths": [
      "The modular architecture of Generator, Reflector, and Curator allows for specialized optimization of context adaptation, preventing a single LLM from being overloaded with all responsibilities (Section 3).",
      "The incremental delta updates and grow-and-refine mechanisms effectively address context collapse and brevity bias, ensuring knowledge accumulation and refinement over time, which is a significant improvement over monolithic rewriting (Section 3.1, 3.2).",
      "The framework’s ability to operate without ground-truth labels by leveraging execution feedback is a key strength, making it suitable for self-improving agents in diverse environments (Section 4, Results on Agent Benchmark)."
    ],
    "weaknesses": [
      "The methodology's strong reliance on a 'reasonably strong Reflector' means that if the Reflector fails to extract meaningful insights, the constructed context can become noisy or harmful, posing a limitation in scenarios with poor feedback signals (Section B, 4.4).",
      "While the paper states that prompts are released, a clear public code repository for the full ACE framework is not explicitly provided, which could hinder full reproducibility by other researchers.",
      "The paper uses a batch size of 1 for constructing delta contexts (Section 4.2), and while it claims multi-delta merging is possible, further analysis on the impact of different batch sizes on efficiency and context quality could be beneficial."
    ]
  },
  "novelty": {
    "rating": "excellent",
    "originality": "ACE introduces a highly original approach to context adaptation by conceptualizing contexts as evolving 'playbooks' rather than static prompts or summaries (Abstract, Section 3). Its modular agentic architecture, comprising Generator, Reflector, and Curator, coupled with incremental delta updates and a grow-and-refine mechanism, represents a novel system design to overcome common issues like brevity bias and context collapse (Section 2.2).",
    "significance": "The contribution is highly significant, offering a scalable, efficient, and self-improving paradigm for LLM systems. ACE's demonstrated ability to achieve high performance with smaller open-source models, while drastically reducing adaptation latency and cost (Table 4), could make advanced LLM applications more accessible and practical for deployment (Section 4).",
    "incremental_vs_breakthrough": "The contribution is a moderate advance, building significantly upon the agentic design of Dynamic Cheatsheet [41] by introducing structured division of labor and mechanisms to prevent context degradation. While not a paradigm shift from scratch, its comprehensive solution to fundamental problems in context adaptation (brevity bias, context collapse) marks a notable progression, enabling new levels of scalability and performance for LLM agents and domain-specific reasoning (Section 2.2, 3).",
    "comparison_to_prior_work": "The paper thoroughly compares ACE to prior works such as Dynamic Cheatsheet (DC) [41], Reflexion [40], TextGrad [54], GEPA [4], and MIPROv2 [36]. It specifically highlights how ACE extends DC's adaptive memory by incorporating a modular workflow and structured, incremental updates to prevent context collapse, a key limitation shown in Figure 2. The paper distinguishes ACE from prompt optimizers like GEPA by focusing on comprehensive, evolving playbooks rather than concise, broadly applicable instructions, directly addressing the brevity bias identified in prior work (Section 2.2)."
  },
  "writing": {
    "rating": "good",
    "clarity": "The writing is generally clear and easy to follow. Key concepts such as 'brevity bias' and 'context collapse' are well-defined and illustrated with examples (Section 2.2, Figure 2). Technical terms are explained, and the overall flow maintains good readability, making complex ideas accessible.",
    "organization": "The paper is well-organized with a logical progression from background and motivation (Section 2) to the proposed framework (Section 3), results (Section 4), and discussion (Section 5). Each section builds coherently on the previous one, and subsections aid in breaking down complex topics. The appendices for prompts are also clearly structured.",
    "grammar_and_style": "The grammar and writing style are professional and consistent throughout the paper, with minimal errors. The tone is academic and objective. Sentence structures are generally sound, contributing to the paper's overall readability and credibility.",
    "suggestions": [
      "Consider consolidating the discussion of 'brevity bias' and 'context collapse' more explicitly in the abstract or introduction to immediately highlight the core problems ACE solves.",
      "Ensure consistent terminology for 'playbook' and 'cheatsheet' where applicable; while 'playbook' is ACE's term, the relation to 'cheatsheet' could be consistently signposted.",
      "Refine the phrasing in Section 4.3 and 4.4, particularly when discussing performance gains, to uniformly indicate whether it's absolute or relative percentage gain, to avoid any ambiguity."
    ]
  },
  "visual_elements": {
    "overall_rating": "good",
    "tables": {
      "rating": "good",
      "quality": "The tables (Table 1, Table 2, Table 3, Table 4) are generally clear and well-organized, effectively presenting quantitative results. Headers are well-defined, and footnotes provide necessary context, such as the meaning of 'GT Labels'. The use of '±' to indicate statistical variation adds valuable detail. They are relevant to the text and support the claims.",
      "issues": [],
      "suggestions": [
        "In Table 1 and Table 2, consider adding a column for 'Relative Improvement (%)' to make the performance gains of ACE over baselines more immediately apparent, beyond the '±' notation."
      ]
    },
    "figures": {
      "rating": "good",
      "quality": "The figures (Figure 1, Figure 2, Figure 4, Figure 5, Figure 6-14) are generally high quality, with clear labels, legends, and resolutions. Figure 1 effectively summarizes overall performance, and Figure 2 clearly illustrates the 'context collapse' phenomenon. Figure 4 provides a comprehensible overview of the ACE framework's architecture.",
      "data_presentation": "Data presentation in figures is effective. Figure 1 uses bar charts appropriately to compare performance across different methods and benchmarks. Figure 2's line plot clearly shows trends in token count and accuracy over adaptation steps. Figure 4's diagram effectively conveys the workflow and modular components of ACE.",
      "issues": [
        "Figure 1's y-axis for 'Accuracy (%)' and the numerical ranges of the right y-axes for 'Domain Knowledge: FINER' and 'Numerical Reasoning: Formula' are slightly offset or unclear in their direct relation to the percentage accuracy, potentially causing momentary confusion for quick interpretation."
      ],
      "suggestions": [
        "For Figure 1, ensure the y-axis ranges for the domain knowledge and numerical reasoning tasks are consistently aligned or clearly distinguished from the main accuracy scale to prevent misinterpretation.",
        "Consider enhancing the visual prominence of the 'Reflector' and 'Curator' components in Figure 4 to emphasize their distinct roles and the modularity that ACE introduces."
      ]
    },
    "diagrams": {
      "rating": "good",
      "quality": "Figure 4 (The ACE Framework) is a clear and effective diagram illustrating the modular architecture and iterative refinement process. The components (Generator, Reflector, Curator) and their interactions (Query, Trajectory, Insights, Update, Delta Context Items) are well-labeled, and the flow is logical. The prompts provided in Figures 6-14 serve as conceptual diagrams of the model's interaction logic.",
      "issues": [],
      "suggestions": [
        "Add a small legend or color-coding to Figure 4 to differentiate between LLM components and process steps, further enhancing clarity."
      ]
    },
    "images": null,
    "visual_consistency": "Visual consistency is good across the paper. Figures and tables generally maintain similar font styles and sizes for labels and text within the visuals. The use of '↑' for improvement and '↓' for reduction is consistent across tables. Colors are used effectively in Figure 1 to distinguish between different methods.",
    "caption_quality": "Caption quality is generally good. Captions are informative and provide sufficient detail for understanding the visual elements without extensive reference to the main text. For example, Figure 1's caption clearly states that it shows 'Overall Performance Results'. Captions for Tables 1 and 2 also provide crucial information about 'GT labels'. Figures 6-14 providing detailed prompts are excellent for reproducibility."
  },
  "literature": {
    "rating": "good",
    "comprehensiveness": "The literature review is comprehensive, covering foundational work in LLM agents (e.g., ReAct [52]), context adaptation methods (e.g., Reflexion [40], GEPA [4]), and the limitations of existing approaches such as brevity bias and context collapse (Section 2.1, 2.2). It also references recent advances in long-context LLMs and memory frameworks (Section 2.1, Related Work).",
    "gaps_identified": [],
    "citation_accuracy": "Citations appear accurate and are appropriately contextualized throughout the paper, supporting claims and providing necessary background. For example, the discussion on 'brevity bias' explicitly cites Gao et al. [16] in Section 2.2, and Dynamic Cheatsheet [41] is correctly identified as a foundational work for ACE in Section 3."
  },
  "results": {
    "rating": "excellent",
    "result_quality": "The results are of high quality and well-presented. They are quantitatively strong, showing consistent and significant performance gains across diverse benchmarks (Tables 1, 2) and reduced costs/latency (Table 4). Error margins are provided, bolstering confidence in the reported improvements. The ablation studies (Table 3) further demonstrate the validity of ACE's design choices.",
    "interpretation": "The interpretation of results is sound and balanced. Authors logically connect performance gains to the strengths of the ACE framework, such as its modularity and incremental updates. They also acknowledge potential limitations, such as the dependence on feedback quality (Section 4.4, B), avoiding over-claiming. The discussion also links the findings to practical implications for scalable and self-improving LLM systems (Section 5).",
    "limitations_assessment": "The limitations are discussed explicitly and realistically in Section B, titled 'Limitations and Challenges'. The paper clearly states ACE's reliance on a 'reasonably strong Reflector' and notes that performance may degrade without reliable execution signals, which is a fair and important acknowledgment. It also identifies scenarios where detailed contexts might be redundant (e.g., simple tasks), providing a balanced perspective.",
    "limitations_discussed": true
  },
  "ethical_considerations": {
    "ethical_concerns": null,
    "data_privacy": "Section 5, 'Discussion,' under 'Implications for Online and Continuous Learning,' mentions that ACE's human-interpretable contexts enable 'selective unlearning [8, 10, 29]—whether due to privacy or legal constraints [1, 2], or when outdated or incorrect information is identified by domain experts.' This implicitly addresses data privacy and the ethical implications of managing information within LLM contexts.",
    "bias_assessment": null,
    "reproducibility_ethics": "The paper provides detailed prompts in Appendix D to support transparency and reproducibility of the language models used for the baselines and the ACE Generator. However, explicit code release for the full ACE framework is not mentioned, which could impede full reproducibility, a key ethical consideration in AI research."
  },
  "overall_assessment": {
    "strengths": [
      "ACE effectively addresses the critical problems of brevity bias and context collapse in LLM context adaptation through its unique evolving playbook framework and modular design (Section 2.2, 3).",
      "The framework demonstrates significant performance improvements across diverse benchmarks (agentic and financial) while simultaneously reducing adaptation latency and cost, offering a highly efficient solution (Table 1, 2, 4).",
      "ACE’s ability to self-improve without labeled supervision, utilizing natural execution feedback, makes it highly versatile and applicable for building robust, autonomous AI agents (Section 4.3).",
      "The paper provides a thorough comparison to strong baselines and includes comprehensive ablation studies, clearly justifying its design choices and validating its contributions (Section 4.2, 4.5).",
      "The architecture with Generator, Reflector, and Curator enables a structured, human-like learning process for LLMs, avoiding the pitfalls of monolithic context rewriting (Section 3)."
    ],
    "weaknesses": [
      "The performance of ACE is highly dependent on the quality of the Reflector and the reliability of feedback signals, which could lead to context pollution in scenarios with weak feedback (Section B, 4.4).",
      "While prompts are provided, the explicit availability of the complete ACE code base is not stated, potentially hindering complete reproducibility by the wider research community.",
      "The paper uses 'DeepSeek-V3.1' as a smaller open-source model; however, a more in-depth discussion on its specific capabilities and how it compares to other open-source models (e.g., Llama, Mistral) in this context could provide further insights.",
      "The discussion on 'Longer Context ≠ Higher Serving Cost' (Section 5) explains mechanisms like KV cache reuse, but without empirical data or specific benchmarks for these claims, it remains largely theoretical within the paper."
    ]
  },
  "ai_generation": {
    "is_likely_ai_generated": false,
    "authenticity_score": "authentic",
    "analysis": "The paper exhibits a natural voice, sophisticated argumentation, and deep domain expertise, characteristic of human authorship. It presents complex technical details, critical analysis of prior work's limitations, and carefully designed experiments with nuanced interpretations. There are no signs of generic phrasing, repetitive patterns, or inconsistent technical depth often associated with AI-generated text. The specific, actionable suggestions for figures and tables also indicate human critical review.",
    "indicators": [
      "Natural voice and novel insights",
      "Sophisticated argumentation",
      "Critical analysis of existing limitations (brevity bias, context collapse)",
      "Detailed experimental design and ablation studies"
    ],
    "confidence": "high"
  },
  "specific_issues": {
    "major_issues": [
      "Issue: The explicit public release of the full ACE framework's code is not clearly stated. Impact: This prevents independent verification and full reproducibility, which is critical for a research contribution.",
      "Issue: The discussion on 'Longer Context ≠ Higher Serving Cost' in Section 5 lacks empirical evidence within the paper to support the claims about reduced inference cost and GPU memory usage. Impact: This weakens the practical benefits claimed for long contexts, as the reader must rely on external references without in-paper validation."
    ],
    "minor_issues": [
      "Figure 1's right-hand y-axes for 'Domain Knowledge: FINER' and 'Numerical Reasoning: Formula' could be more clearly aligned or scaled to avoid visual ambiguity regarding their percentage values.",
      "Consider adding a small legend or color-coding to Figure 4 to differentiate between LLM components and process steps for enhanced clarity.",
      "Ensure consistent use of 'percentage points' versus 'percent' when discussing performance gains to maintain precise statistical language.",
      "In Section 4.6, 'token ingestion/generation' is mentioned; consider clarifying if 'token dollar costs' primarily refers to API costs (e.g., for DeepSeek-V3.1) or internal compute costs."
    ],
    "questions_for_authors": [
      "Could the authors provide a public GitHub repository link for the ACE framework, including the Generator, Reflector, and Curator implementations, to enhance reproducibility?",
      "For the 'grow-and-refine' mechanism, what specific thresholds or criteria are used to trigger the de-duplication step proactively versus lazily, and how does this choice impact performance on different tasks (Section 3.2)?",
      "Could the authors elaborate on the 'DeepSeek-V3.1' model, particularly its architectural details and how it was fine-tuned or adapted for ACE, or how it compares to other leading open-source models in terms of underlying capabilities relevant to this work?",
      "What are the specific 'semantic embeddings' used for comparing and pruning bullets in the grow-and-refine mechanism, and how robust is this to nuanced differences in strategies (Section 3.2)?"
    ]
  },
  "detailed_feedback": {
    "comments_for_authors": "This paper presents Agentic Context Engineering (ACE), a highly promising framework for addressing critical limitations in LLM context adaptation. The core idea of evolving playbooks with a modular Generator-Reflector-Curator architecture is novel and well-motivated, successfully tackling brevity bias and context collapse. The empirical results are compelling, demonstrating substantial performance gains on agentic and domain-specific tasks, coupled with impressive reductions in adaptation latency and cost. The ablation studies effectively highlight the contributions of ACE's distinct design choices. The explicit discussion of limitations, particularly the reliance on reliable feedback, shows a balanced perspective. For improvement, I recommend explicitly releasing the ACE codebase for full reproducibility. While Figure 1 is effective, refining the alignment of the right y-axes would improve immediate clarity. Expanding the discussion on the 'DeepSeek-V3.1' model's specifics and adding empirical validation for the 'Longer Context ≠ Higher Serving Cost' claims would further strengthen the paper. Finally, clarifying the criteria for the grow-and-refine mechanism’s de-duplication would be beneficial. Overall, this is a very strong paper with significant contributions to the field of self-improving LLM systems.",
    "confidential_comments_to_editor": "This paper is a strong candidate for acceptance. The methodology is innovative, and the results are significant and well-supported by robust experimental design and ablation studies. The authors effectively address a critical and timely problem in LLM development. While minor revisions are suggested, they do not detract from the core contribution. The transparency in providing prompts (Appendix D) is appreciated, though a full code release would be ideal."
  },
  "recommendation": {
    "decision": "accept",
    "confidence": "high",
    "justification": "The paper presents a novel and well-validated framework that significantly advances context adaptation for LLMs, addressing critical limitations of prior work. Its strong empirical results across diverse benchmarks, combined with efficiency gains and a robust methodology, make it a valuable contribution to the field. Minor revisions for clarity and reproducibility will further enhance its impact.",
    "conditions_for_acceptance": null
  }
}